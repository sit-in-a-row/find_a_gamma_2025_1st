{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387bb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# 설정\n",
    "START_DATE = '2025-05-25'\n",
    "END_DATE = '2025-06-27'\n",
    "SYMBOL = 'SPY'\n",
    "OUTPUT_DIR_OPT = './SPY_option_data'\n",
    "OUTPUT_DIR_VOL = './SPY_option_vol_data'\n",
    "OUTPUT_DIR_SPOT = './SPY_SPOT_df.csv'\n",
    "OUTPUT_DIR_GEX = './SPY_GEX_df.csv'\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# 디렉토리 준비\n",
    "os.makedirs(OUTPUT_DIR_OPT, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_VOL, exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# 날짜 리스트 생성\n",
    "def generate_date_list(start_date, end_date):\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    date_list = []\n",
    "    while start <= end:\n",
    "        date_list.append(start.strftime('%Y-%m-%d'))\n",
    "        start += timedelta(days=1)\n",
    "    return date_list\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# API 요청 + 저장\n",
    "def fetch_and_save(OUTPUT_DIR, date_str, type_=\"option_chain\"):\n",
    "    # 저장할 파일 경로\n",
    "    file_path = os.path.join(OUTPUT_DIR, f\"{date_str}.json\")\n",
    "    # 이미 있으면 건너뛰기\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[{date_str}] 정보 이미 있음! 건너뜁니당\")\n",
    "        return False\n",
    "\n",
    "    base_url = 'https://www.dolthub.com/api/v1alpha1/post-no-preference/options/master'\n",
    "    sql_query = f\"select * from {type_} where act_symbol = '{SYMBOL}' and date = '{date_str}'\"\n",
    "    params = {'q': sql_query}\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(base_url, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        \n",
    "        # 성공한 경우만 rows가 있으면 저장\n",
    "        if 'rows' in data and data['rows']:\n",
    "            os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(data['rows'], f, indent=2)\n",
    "            print(f\"[{date_str}] saved ({len(data['rows'])} rows).\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"[{date_str}] no data.\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{date_str}] Error: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────\n",
    "# 메인 루프 (옵션/변동성 데이터 수집)\n",
    "if __name__ == \"__main__\":\n",
    "    date_list = generate_date_list(START_DATE, END_DATE)\n",
    "    print(f\"총 {len(date_list)}일 데이터 요청 시작...\")\n",
    "\n",
    "    for date in tqdm(date_list):\n",
    "        success_OPT = fetch_and_save(OUTPUT_DIR_OPT, date)\n",
    "        success_VOL = fetch_and_save(OUTPUT_DIR_VOL, date, 'volatility_history')\n",
    "        if not success_OPT or not success_VOL:\n",
    "            # 데이터 없거나 에러인 경우 pass\n",
    "            continue\n",
    "\n",
    "    print(f\"✅ 데이터 수집 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29517e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────\n",
    "# 현물 데이터 수집\n",
    "price_df = fdr.DataReader('YAHOO:SPY')\n",
    "price_df.to_csv(OUTPUT_DIR_SPOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ab2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────\n",
    "# GEX 데이터 수집\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_gamma_exposure():\n",
    "    url = \"https://unusualwhales.com/stock/SPY/greek-exposure?tab=Gamma\"\n",
    "\n",
    "    # 크롬 드라이버 옵션\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument('--headless')  # 헤드리스 실행 시 주석 해제\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "\n",
    "    # 페이지 접속 및 로드 대기\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Daily Gamma Exposure Table 그리드 로드\n",
    "    grid_xpath = (\n",
    "        \"//div[contains(@class,'card_cardTitleText')\"\n",
    "        \" and normalize-space(text())='Daily Gamma Exposure Table - SPY']\"\n",
    "        \"/ancestor::section//div[@role='grid']\"\n",
    "    )\n",
    "    grid = wait.until(EC.presence_of_element_located((By.XPATH, grid_xpath)))\n",
    "\n",
    "    # 스크롤 및 파싱 설정\n",
    "    seen_dates = set()\n",
    "    records = []\n",
    "    scroll_increment = 300  # 픽셀 단위 스크롤 양\n",
    "\n",
    "    # 전체 스크롤 영역 크기\n",
    "    scroll_height = driver.execute_script(\"return arguments[0].scrollHeight\", grid)\n",
    "    scroll_position = 0\n",
    "\n",
    "    # 반복해서 스크롤하며 데이터 파싱\n",
    "    while scroll_position <= scroll_height:\n",
    "        rows = grid.find_elements(By.XPATH, \".//div[@role='row' and not(contains(@class,'rdg-header-row'))]\")\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.XPATH, \".//div[@role='gridcell']\")\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "            date = cells[0].text.strip()\n",
    "            if date not in seen_dates:\n",
    "                seen_dates.add(date)\n",
    "                records.append({\n",
    "                    \"Date\": date,\n",
    "                    \"Call GEX\": cells[1].text.strip(),\n",
    "                    \"Put GEX\": cells[2].text.strip(),\n",
    "                    \"Net GEX\": cells[3].text.strip(),\n",
    "                    \"P/C GEX\": cells[4].text.strip()\n",
    "                })\n",
    "        # 스크롤 다운\n",
    "        scroll_position += scroll_increment\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[1]\", grid, scroll_position)\n",
    "        time.sleep(1)\n",
    "        scroll_height = driver.execute_script(\"return arguments[0].scrollHeight\", grid)\n",
    "\n",
    "    # DataFrame 생성 및 인덱스 설정\n",
    "    df = pd.DataFrame(records)\n",
    "    df = df.drop_duplicates(subset=[\"Date\"])  # 중복 제거\n",
    "    df = df.sort_values(by=\"Date\", ascending=False)\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    driver.quit()\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = fetch_gamma_exposure()\n",
    "    df.to_csv(OUTPUT_DIR_GEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2c338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
